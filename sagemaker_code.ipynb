{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f517372e",
   "metadata": {},
   "source": [
    "# 画像分類AIアプリ\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fae9ca",
   "metadata": {},
   "source": [
    "## S3バケット、Dockerを指定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9030e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "811284229777.dkr.ecr.us-east-1.amazonaws.com/image-classification:latest\n",
      "CPU times: user 977 ms, sys: 149 ms, total: 1.13 s\n",
      "Wall time: 8.29 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import boto3\n",
    "import re\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "bucket='sagemaker-binary-classification-3-3'\n",
    "\n",
    "containers = {'us-west-2': '433757028032.dkr.ecr.us-west-2.amazonaws.com/image-classification:latest',\n",
    "              'us-east-1': '811284229777.dkr.ecr.us-east-1.amazonaws.com/image-classification:latest',\n",
    "              'us-east-2': '825641698319.dkr.ecr.us-east-2.amazonaws.com/image-classification:latest',\n",
    "              'eu-west-1': '685385470294.dkr.ecr.eu-west-1.amazonaws.com/image-classification:latest'}\n",
    "training_image = containers[boto3.Session().region_name]\n",
    "print(training_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab668bf",
   "metadata": {},
   "source": [
    "## トレーニング用のパラメータを指定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "958ba488",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2\n",
    "\n",
    "# The algorithm supports multiple network depth (number of layers). They are 18, 34, 50, 101, 152 and 200\n",
    "# For this training, we will use 18 layers\n",
    "num_layers = 50\n",
    "# we need to specify the input image shape for the training data\n",
    "\n",
    "#train_images_224.rec\n",
    "image_shape = \"3,224,224\"\n",
    "\n",
    "# we also need to specify the number of training samples in the training set\n",
    "num_training_samples = 1891 ##二値分類\n",
    "\n",
    "# specify the number of output classes\n",
    "num_classes = 2\n",
    "\n",
    "# batch size for training\n",
    "mini_batch_size =  16 \n",
    "\n",
    "# number of epochs\n",
    "epochs = 10\n",
    "\n",
    "# learning rate\n",
    "learning_rate = 0.01\n",
    "# Since we are using transfer learning, we set use_pretrained_model to 1 so that weights can be \n",
    "# initialized with pre-trained weights\n",
    "use_pretrained_model = 1\n",
    "# Training algorithm/optimizer. Default is SGD\n",
    "optimizer = 'sgd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0816cb28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training job name: sagemaker-inst-2022-04-18-01-38-34\n",
      "\n",
      "Input Data Location: {'S3DataType': 'S3Prefix', 'S3Uri': 's3://sagemaker-binary-classification-3-3/train', 'S3DataDistributionType': 'FullyReplicated'}\n",
      "CPU times: user 60.1 ms, sys: 14.9 ms, total: 75 ms\n",
      "Wall time: 211 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import time\n",
    "import boto3\n",
    "from time import gmtime, strftime\n",
    "\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "# create unique job name \n",
    "job_name_prefix = 'sagemaker-inst'\n",
    "timestamp = time.strftime('-%Y-%m-%d-%H-%M-%S', time.gmtime())\n",
    "job_name = job_name_prefix + timestamp\n",
    "training_params = \\\n",
    "{\n",
    "    # specify the training docker image\n",
    "    \"AlgorithmSpecification\": {\n",
    "        \"TrainingImage\": training_image,\n",
    "        \"TrainingInputMode\": \"File\"\n",
    "    },\n",
    "    \"RoleArn\": role,\n",
    "    \"OutputDataConfig\": {\n",
    "        \"S3OutputPath\": 's3://{}/{}/output'.format(bucket, job_name_prefix)\n",
    "    },\n",
    "    \"ResourceConfig\": {\n",
    "        \"InstanceCount\": 1,\n",
    "        \"InstanceType\": \"ml.p2.8xlarge\",\n",
    "        \"VolumeSizeInGB\": 50\n",
    "    },\n",
    "    \"TrainingJobName\": job_name,\n",
    "    \"HyperParameters\": {\n",
    "        \"image_shape\": image_shape,\n",
    "        \"num_layers\": str(num_layers),\n",
    "        \"num_training_samples\": str(num_training_samples),\n",
    "        \"num_classes\": str(num_classes),\n",
    "        \"mini_batch_size\": str(mini_batch_size),\n",
    "        \"epochs\": str(epochs),\n",
    "        \"learning_rate\": str(learning_rate),\n",
    "        \"use_pretrained_model\": str(use_pretrained_model)\n",
    "    },\n",
    "    \"StoppingCondition\": {\n",
    "        \"MaxRuntimeInSeconds\": 360000\n",
    "    },\n",
    "#Training data should be inside a subdirectory called \"train\"\n",
    "#Validation data should be inside a subdirectory called \"validation\"\n",
    "#The algorithm currently only supports fullyreplicated model (where data is copied onto each machine)\n",
    "    \"InputDataConfig\": [\n",
    "        {\n",
    "            \"ChannelName\": \"train\",\n",
    "            \"DataSource\": {\n",
    "                \"S3DataSource\": {\n",
    "                    \"S3DataType\": \"S3Prefix\",\n",
    "                    \"S3Uri\": 's3://{}/train'.format(bucket),\n",
    "                    \"S3DataDistributionType\": \"FullyReplicated\"\n",
    "                }\n",
    "            },\n",
    "            \"ContentType\": \"application/x-recordio\",\n",
    "            \"CompressionType\": \"None\"\n",
    "        },\n",
    "        {\n",
    "            \"ChannelName\": \"validation\",\n",
    "            \"DataSource\": {\n",
    "                \"S3DataSource\": {\n",
    "                    \"S3DataType\": \"S3Prefix\",\n",
    "                    \"S3Uri\": 's3://{}/validation'.format(bucket),\n",
    "                    \"S3DataDistributionType\": \"FullyReplicated\"\n",
    "                }\n",
    "            },\n",
    "            \"ContentType\": \"application/x-recordio\",\n",
    "            \"CompressionType\": \"None\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "print('Training job name: {}'.format(job_name))\n",
    "print('\\nInput Data Location: {}'.format(training_params['InputDataConfig'][0]['DataSource']['S3DataSource']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db93264",
   "metadata": {},
   "source": [
    "## トレーニングの開始"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f74e81b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceLimitExceeded",
     "evalue": "An error occurred (ResourceLimitExceeded) when calling the CreateTrainingJob operation: The account-level service limit 'ml.p2.8xlarge for training job usage' is 0 Instances, with current utilization of 0 Instances and a request delta of 1 Instances. Please contact AWS support to request an increase for this limit.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceLimitExceeded\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-33f34d1c4118>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# create the Amazon SageMaker training job\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msagemaker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mboto3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mservice_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sagemaker'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0msagemaker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_training_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtraining_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# confirm that the training job has started\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    399\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    400\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    729\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 731\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    732\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceLimitExceeded\u001b[0m: An error occurred (ResourceLimitExceeded) when calling the CreateTrainingJob operation: The account-level service limit 'ml.p2.8xlarge for training job usage' is 0 Instances, with current utilization of 0 Instances and a request delta of 1 Instances. Please contact AWS support to request an increase for this limit."
     ]
    }
   ],
   "source": [
    "#4\n",
    "\n",
    "# create the Amazon SageMaker training job\n",
    "sagemaker = boto3.client(service_name='sagemaker')\n",
    "sagemaker.create_training_job(**training_params)\n",
    "\n",
    "# confirm that the training job has started\n",
    "status = sagemaker.describe_training_job(TrainingJobName=job_name)['TrainingJobStatus']\n",
    "print('Training job current status: {}'.format(status))\n",
    "\n",
    "try:\n",
    "    # wait for the job to finish and report the ending status\n",
    "    sagemaker.get_waiter('training_job_completed_or_stopped').wait(TrainingJobName=job_name)\n",
    "    training_info = sagemaker.describe_training_job(TrainingJobName=job_name)\n",
    "    status = training_info['TrainingJobStatus']\n",
    "    print(\"Training job ended with status: \" + status)\n",
    "except:\n",
    "    print('Training failed to start')\n",
    "     # if exception is raised, that means it has failed\n",
    "    message = sagemaker.describe_training_job(TrainingJobName=job_name)['FailureReason']\n",
    "    print('Training failed with the following error: {}'.format(message))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d2495e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5\n",
    "\n",
    "training_info = sagemaker.describe_training_job(TrainingJobName=job_name)\n",
    "status = training_info['TrainingJobStatus']\n",
    "print(\"Training job ended with status: \" + status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92743bf6",
   "metadata": {},
   "source": [
    "### トレインデータと検証データの精度確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e3f6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6\n",
    "\n",
    "import boto3\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "client = boto3.client('logs')\n",
    "\n",
    "lgn='/aws/sagemaker/TrainingJobs'\n",
    "\n",
    "# Update this with the actual name in CloudWatch logs\n",
    "lsn=job_name+'/'+'algo-1-1646501929'\n",
    "log=client.get_log_events(logGroupName=lgn, logStreamName=lsn)\n",
    "\n",
    "trn_accs=[]\n",
    "val_accs=[]\n",
    "for e in log['events']:\n",
    "  msg=e['message']\n",
    "  if 'Validation-accuracy' in msg:\n",
    "        val = msg.split(\"=\")\n",
    "        val = val[1]\n",
    "        val_accs.append(float(val))\n",
    "  if 'Train-accuracy' in msg:\n",
    "        trn = msg.split(\"=\")\n",
    "        trn = trn[1]\n",
    "        trn_accs.append(float(trn))\n",
    "\n",
    "print(\"Maximum validation accuracy: %f \" % max(val_accs))\n",
    "plt.clf()\n",
    "fig, ax = plt.subplots()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "trn_plot, = ax.plot(range(epochs), trn_accs, label=\"Training accuracy\")\n",
    "val_plot, = ax.plot(range(epochs), val_accs, label=\"Validation accuracy\")\n",
    "plt.legend(handles=[trn_plot,val_plot])\n",
    "ax.yaxis.set_ticks(np.arange(0.4, 1.05, 0.05))\n",
    "ax.yaxis.set_major_formatter(ticker.FormatStrFormatter('%0.2f'))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92f7c08",
   "metadata": {},
   "source": [
    "### 推論"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbda64b",
   "metadata": {},
   "source": [
    "### モデル作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7775bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#7\n",
    "\n",
    "%%time\n",
    "import boto3\n",
    "from time import gmtime, strftime\n",
    "\n",
    "sage = boto3.Session().client(service_name='sagemaker') \n",
    "\n",
    "model_name=\"image-classification-cifar-transfer\"\n",
    "print(model_name)\n",
    "info = sage.describe_training_job(TrainingJobName=job_name)\n",
    "model_data = info['ModelArtifacts']['S3ModelArtifacts']\n",
    "print(model_data)\n",
    "containers = {'us-west-2': '433757028032.dkr.ecr.us-west-2.amazonaws.com/image-classification:latest',\n",
    "              'us-east-1': '811284229777.dkr.ecr.us-east-1.amazonaws.com/image-classification:latest',\n",
    "              'us-east-2': '825641698319.dkr.ecr.us-east-2.amazonaws.com/image-classification:latest',\n",
    "              'eu-west-1': '685385470294.dkr.ecr.eu-west-1.amazonaws.com/image-classification:latest'}\n",
    "hosting_image = containers[boto3.Session().region_name]\n",
    "primary_container = {\n",
    "    'Image': hosting_image,\n",
    "    'ModelDataUrl': model_data,\n",
    "}\n",
    "\n",
    "create_model_response = sage.create_model(\n",
    "    ModelName = model_name,\n",
    "    ExecutionRoleArn = role,\n",
    "    PrimaryContainer = primary_container)\n",
    "\n",
    "print(create_model_response['ModelArn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbb3cca",
   "metadata": {},
   "source": [
    "### エンドポイントの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d319e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8\n",
    "\n",
    "from time import gmtime, strftime\n",
    "\n",
    "timestamp = time.strftime('-%Y-%m-%d-%H-%M-%S', time.gmtime())\n",
    "endpoint_config_name = job_name_prefix + '-epc-' + timestamp\n",
    "endpoint_config_response = sage.create_endpoint_config(\n",
    "    EndpointConfigName = endpoint_config_name,\n",
    "    ProductionVariants=[{\n",
    "        'InstanceType':'ml.m4.xlarge',\n",
    "        'InitialInstanceCount':1,\n",
    "        'ModelName':model_name,\n",
    "        'VariantName':'AllTraffic'}])\n",
    "\n",
    "print('Endpoint configuration name: {}'.format(endpoint_config_name))\n",
    "print('Endpoint configuration arn:  {}'.format(endpoint_config_response['EndpointConfigArn']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e18e27",
   "metadata": {},
   "source": [
    "### エンドポイントの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996aef93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#9\n",
    "\n",
    "%%time\n",
    "import time\n",
    "\n",
    "timestamp = time.strftime('-%Y-%m-%d-%H-%M-%S', time.gmtime())\n",
    "endpoint_name = job_name_prefix + '-ep-' + timestamp\n",
    "print('Endpoint name: {}'.format(endpoint_name))\n",
    "\n",
    "endpoint_params = {\n",
    "    'EndpointName': endpoint_name,\n",
    "    'EndpointConfigName': endpoint_config_name,\n",
    "}\n",
    "endpoint_response = sagemaker.create_endpoint(**endpoint_params)\n",
    "print('EndpointArn = {}'.format(endpoint_response['EndpointArn']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17c489d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#10\n",
    "\n",
    "# get the status of the endpoint\n",
    "response = sagemaker.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = response['EndpointStatus']\n",
    "print('EndpointStatus = {}'.format(status))\n",
    "\n",
    "\n",
    "# wait until the status has changed\n",
    "sagemaker.get_waiter('endpoint_in_service').wait(EndpointName=endpoint_name)\n",
    "\n",
    "\n",
    "# print the status of the endpoint\n",
    "endpoint_response = sagemaker.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = endpoint_response['EndpointStatus']\n",
    "print('Endpoint creation ended with EndpointStatus = {}'.format(status))\n",
    "\n",
    "if status != 'InService':\n",
    "    raise Exception('Endpoint creation failed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14471bdc",
   "metadata": {},
   "source": [
    "### テストデータを使って精度確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583327f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#11\n",
    "mport boto3\n",
    "runtime = boto3.Session().client(service_name='runtime.sagemaker') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fc6ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#12\n",
    "s3_client = boto3.client('s3')\n",
    "data_bucket_name='sagemaker-binary-classification-3-3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1448f49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#13\n",
    "obj_list=s3_client.list_objects(Bucket=data_bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa5ed22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#14\n",
    "test_img_list=[]\n",
    "test_label_list=[]\n",
    "test_label_list_num=[]\n",
    "for contents in obj_list['Contents']:\n",
    "    if contents['Key'].split('/')[1] == 'guitar':\n",
    "        test_img_list.append(contents['Key'])\n",
    "        test_label_list.append( 'guitar')\n",
    "        test_label_list_num.append(0)\n",
    "    elif contents['Key'].split('/')[1] == 'others':\n",
    "        test_img_list.append(contents['Key'])\n",
    "        test_label_list.append('others')\n",
    "        test_label_list_num.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4b1955",
   "metadata": {},
   "outputs": [],
   "source": [
    "#15\n",
    "test_img_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba100e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#16\n",
    "test_label_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d551852",
   "metadata": {},
   "outputs": [],
   "source": [
    "#17\n",
    "test_label_list_num[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefafd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#18\n",
    "from PIL import Image\n",
    "from sklearn import model_selection\n",
    "import io\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "def predict(test_img):\n",
    "    response = s3_client.get_object(Bucket=data_bucket_name, Key=test_img)\n",
    "    response_body = response[\"Body\"].read()\n",
    "    payload = bytearray(response_body)\n",
    "    response = runtime.invoke_endpoint(EndpointName=endpoint_name, \n",
    "                                   ContentType='application/x-image', \n",
    "                                   Body=payload )\n",
    "    result = response['Body'].read()\n",
    "    result = json.loads(result)\n",
    "    index = np.argmax(result)\n",
    "    object_categories = ['guitar','others']\n",
    "    return  object_categories[index], result[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1549ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#19\n",
    "test_pred_list = []\n",
    "test_proba_others_list = []\n",
    "for img  in test_img_list:\n",
    "    predict_label,  predict_proba_others = predict(img)\n",
    "    test_pred_list.append(predict_label) \n",
    "    test_proba_others_list.append(predict_proba_others)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559c71fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#20\n",
    "import sklearn.metrics as me\n",
    "cf_matrix = me.confusion_matrix(test_label_list, test_pred_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dc0aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#21\n",
    "cf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec3ebe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#22\n",
    "def plot_confusion_matrix(data, labels):\n",
    "    sns.set(color_codes=True)\n",
    "    plt.figure(1, figsize=(12, 8))\n",
    " \n",
    "    plt.title(\"Confusion Matrix\",  fontsize=18)\n",
    " \n",
    "    sns.set(font_scale=1.4)\n",
    "    ax = sns.heatmap(data, annot=True, cmap=\"YlGnBu\", cbar_kws={'label': 'Scale'})\n",
    " \n",
    "    ax.set_xticklabels(labels, fontsize=18)\n",
    "    ax.set_yticklabels(labels, fontsize=18)\n",
    " \n",
    "    ax.set(ylabel=\"True Label\", xlabel=\"Predicted Label\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f295bf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#23\n",
    "labels = ['guitar','others']\n",
    "plot_confusion_matrix(cf_matrix, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71801ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#24\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(test_label_list, test_pred_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfd46b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#25\n",
    "from sklearn.metrics import roc_auc_score\n",
    "auc_score = roc_auc_score(test_label_list_num, test_proba_others_list)\n",
    "print('AUC : {}'.format(auc_score))\n",
    "\n",
    "fpr_all, tpr_all, th_all  = me.roc_curve(test_label_list_num, test_proba_others_list, pos_label=1)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(fpr_all, tpr_all, marker='o')\n",
    "plt.xlabel('FPR: False positive rate')\n",
    "plt.ylabel('TPR: True positive rate')\n",
    "plt.grid()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
